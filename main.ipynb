{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3839a6-9146-4f60-b74b-19abbc24278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from dotenv import dotenv_values\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from docx import Document\n",
    "from retry import retry\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = config[\"API_BASE\"]\n",
    "openai.api_version = config[\"API_VERSION\"]\n",
    "openai.api_key = config[\"API_KEY\"]\n",
    "\n",
    "completions_deployment_name = config[\"COMPLETIONS_DEPLOYMENT_NAME\"]\n",
    "embeddings_deployment_name = config[\"EMBEDDINGS_DEPLOYMENT_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19473649",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"gpt2\") # encoding for text-davinci-003\n",
    "contents = {\n",
    "    'title': [],\n",
    "    'section': [],\n",
    "    'text': [],\n",
    "    'tokens': []\n",
    "}\n",
    "section = ''\n",
    "text = ''\n",
    "\n",
    "doc = Document('./data/dtic_gameplan.docx')\n",
    "\n",
    "for content in doc.paragraphs:\n",
    "\n",
    "    if (content.style.name=='Heading 1' and \\\n",
    "         not \"Customer & Engagement Overview\" in content.text and \\\n",
    "         not \"Proposed Architecture and Dev Plan\" in content.text) or \\\n",
    "         content.style.name=='Heading 2':\n",
    "\n",
    "        if content.text:\n",
    "            if section:\n",
    "                text = text.strip()\n",
    "                tokens = len(encoding.encode(text))\n",
    "                contents['title'].append('dtic_gameplan.docx')\n",
    "                contents['section'].append(section)\n",
    "                contents['text'].append(text)\n",
    "                contents['tokens'].append(tokens)\n",
    "            section = content.text\n",
    "            text = ''\n",
    "\n",
    "    else:\n",
    "        text += f\"{content.text} \"\n",
    "\n",
    "df = pd.DataFrame.from_dict(contents)\n",
    "df = df.set_index([\"title\", \"section\"])\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba475f30-ef7f-431c-b60d-d5970b62ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(tries=3, delay=1)    # OpenAI seems to occasionally throw APIConnectionError for no good reason\n",
    "@sleep_and_retry\n",
    "@limits(calls=50, period=60)    # documented rate limit is 300/minute but... nope more like 50 <sigh>\n",
    "def get_embedding(input: str, engine: str=embeddings_deployment_name) -> list[float]: # type: ignore\n",
    "    result = openai.Embedding.create(\n",
    "      engine=engine,\n",
    "      input=input\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"] # type: ignore\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    return {\n",
    "        idx: get_embedding(r.text) for idx, r in df.iterrows()\n",
    "    } # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab50bfca-cb02-41c6-b338-4400abe1d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = compute_doc_embeddings(df[(df['tokens'] > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c0509-eeb9-4552-a5d4-6ace04ef73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SECTION_LEN = 500\n",
    "SEPARATOR = \"\\n* \"\n",
    "separator_len = len(encoding.encode(SEPARATOR))\n",
    "\n",
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]: # type: ignore\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items() # type: ignore\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities # type: ignore\n",
    "\n",
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections: # type: ignore\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.text.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\"\n",
    "\n",
    "\n",
    "\n",
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 500,\n",
    "    \"engine\": completions_deployment_name\n",
    "}\n",
    "\n",
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings: dict[(str, str), np.array], # type: ignore\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    \n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\") # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233e449-bf33-4c9e-b095-6a4dd278c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_query_with_context(\"What user personas exist in this project?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_query_with_context(\"What Azure resources will use private endpoints?\", df, document_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
